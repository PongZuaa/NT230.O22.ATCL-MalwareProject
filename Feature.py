import argparse
import os
import pefile
import hashlib
import csv
import math

output_csv_file = "output_dataset_header.csv"
CPU_TYPE_MAPPING = {
    "UNKNOWN": 0,
    "I386": 0x14C,
    "R3000": 0x162,
    "R4000": 0x166,
    "R10000": 0x168,
    "WCEMIPSV2": 0x169,
    "ALPHA": 0x184,
    "ALPHA64": 0x284,
    "ARM": 0x1C0,
    "IA64": 0x200,
    "MIPS16": 0x266,
    "MIPSFPU": 0x366,
    "MIPSFPU16": 0x466,
    "POWERPC": 0x1F0,
    "POWERPCFP": 0x1F1,
    "SH3": 0x1A2,
    "SH3DSP": 0x1A3,
    "SH4": 0x1A6,
    "SH5": 0x1A8,
    "THUMB": 0x1C2,
    "AMD64": 0x8664,
    # Thêm các giá trị khác tương ứng với CPU type
}

DLL_CHARACTERISTICS_FLAGS = {
    0x0001: "IMAGE_FILE_RELOCS_STRIPPED",
    0x0002: "IMAGE_FILE_EXECUTABLE_IMAGE",
    0x0004: "IMAGE_FILE_LINE_NUMS_STRIPPED",
    0x0008: "IMAGE_FILE_LOCAL_SYMS_STRIPPED",
    0x0010: "IMAGE_FILE_AGGRESSIVE_WS_TRIM",
    0x0020: "IMAGE_FILE_LARGE_ADDRESS_ ",
    0x0040: "IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE",
    0x0080: "IMAGE_FILE_BYTES_REVERSED_LO",
    0x0100: "IMAGE_FILE_32BIT_MACHINE",
    0x0200: "IMAGE_FILE_DEBUG_STRIPPED",
    0x0400: "IMAGE_FILE_REMOVABLE_RUN_ ",
    0x0800: "IMAGE_FILE_NET_RUN_FROM_SWAP",
    0x1000: "IMAGE_FILE_SYSTEM",
    0x2000: "IMAGE_FILE_DLL",
    0x4000: "IMAGE_FILE_UP_SYSTEM_ONLY",
    0x8000: "IMAGE_FILE_BYTES_REVERSED_HI",
}

def get_version_info(pe):
    """Return version infos"""
    res = {}
    for fileinfo in pe.FileInfo:
        if fileinfo.Key == 'StringFileInfo':
            for st in fileinfo.StringTable:
                for entry in st.entries.items():
                    res[entry[0]] = entry[1]
        if fileinfo.Key == 'VarFileInfo':
            for var in fileinfo.Var:
                res[var.entry.items()[0][0]] = var.entry.items()[0][1]
    if hasattr(pe, 'VS_FIXEDFILEINFO'):
        res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags
        res['os'] = pe.VS_FIXEDFILEINFO.FileOS
        res['type'] = pe.VS_FIXEDFILEINFO.FileType
        res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS
        res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS
        res['signature'] = pe.VS_FIXEDFILEINFO.Signature
        res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion
    return res

def extract_pe_fields(name_file_PE, file_path, file_type):
    # Tạo đối tượng PE từ file
    pe = None
    try:
        pe = pefile.PE(file_path)
    except Exception as e:
        return None

    # Tính MD5 của dữ liệu file
    md5 = hashlib.md5()
    with open(file_path, 'rb') as file:
        while True:
            chunk = file.read(8192)
            if not chunk:
                break
            md5.update(chunk)
    md5_hash = md5.hexdigest()

    # Xác định loại file PE dựa trên thuộc tính Magic
    if pe.OPTIONAL_HEADER.Magic == pefile.OPTIONAL_HEADER_MAGIC_PE:
        pe_type = "PE"
    elif pe.OPTIONAL_HEADER.Magic == pefile.OPTIONAL_HEADER_MAGIC_PE_PLUS:
        pe_type = "PE+"
    else:
        pe_type = "Unknown"
        
    file_header = pe.FILE_HEADER
    machine_type = pe.FILE_HEADER.Machine
    cpu_type = pefile.MACHINE_TYPE.get(machine_type, "Unknown CPU Type")
    if cpu_type.startswith("IMAGE_FILE_MACHINE_"):
        cpu_type = cpu_type[len("IMAGE_FILE_MACHINE_"):]

    #cpu_type_value = CPU_TYPE_MAPPING.get(cpu_type, 0)
    if cpu_type == "I386":
        cpu_type_value = 0x14C
    elif cpu_type == "R3000":
        cpu_type_value = 0x162
    elif cpu_type == "R4000":
        cpu_type_value = 0x166
    elif cpu_type == "R10000":
        cpu_type_value = 0x168
    elif cpu_type == "WCEMIPSV2":
        cpu_type_value = 0x169
    elif cpu_type == "ALPHA":
        cpu_type_value = 0x184
    elif cpu_type == "ALPHA64":
        cpu_type_value = 0x284
    elif cpu_type == "ARM":
        cpu_type_value = 0x1C0
    elif cpu_type == "IA64":
        cpu_type_value = 0x200
    elif cpu_type == "MIPS16":
        cpu_type_value = 0x266
    elif cpu_type == "MIPSFPU":
        cpu_type_value = 0x366
    elif cpu_type == "MIPSFPU16":
        cpu_type_value = 0x466
    elif cpu_type == "POWERPC":
        cpu_type_value = 0x1F0
    elif cpu_type == "POWERPCFP":
        cpu_type_value = 0x1F1
    elif cpu_type == "SH3":
        cpu_type_value = 0x1A2
    elif cpu_type == "SH3DSP":
        cpu_type_value = 0x1A3
    elif cpu_type == "SH4":
        cpu_type_value = 0x1A6
    elif cpu_type == "SH5":
        cpu_type_value = 0x1A8
    elif cpu_type == "THUMB":
        cpu_type_value = 0x1C2
    elif cpu_type == "AMD64":
        cpu_type_value = 0x8664

    # Trích xuất các trường thông tin khác
    characteristics = pe.OPTIONAL_HEADER.DllCharacteristics

    major_linker_version = pe.OPTIONAL_HEADER.MajorLinkerVersion
    minor_linker_version = pe.OPTIONAL_HEADER.MinorLinkerVersion
    size_of_code = pe.OPTIONAL_HEADER.SizeOfCode
    size_of_initialized_data = pe.OPTIONAL_HEADER.SizeOfInitializedData
    size_of_uninitialized_data = pe.OPTIONAL_HEADER.SizeOfUninitializedData
    entropy = map(lambda x: x.get_entropy(), pe.sections)
    raw_sizes = map(lambda x: x.SizeOfRawData, pe.sections)
    virtual_sizes = map(lambda x: x.Misc_VirtualSize, pe.sections)
    res = {}
    try:
        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)
        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])
        res['ImportsNb'] = len(imports)
        res['ImportsNbOrdinal'] = len(list(filter(lambda x: x.name is None, imports)))
    except AttributeError:
        res['ImportsNbDLL'] = 0
        res['ImportsNb'] = 0
        res['ImportsNbOrdinal'] = 0
    try:
        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)
    except AttributeError:
        # No export
        res['ExportNb'] = 0
    resources = get_resources(pe)
    res['ResourcesNb'] = len(resources)
    if len(resources) > 0:
        entropy = list(map(lambda x: x[0], resources))
        res['ResourcesMeanEntropy'] = sum(entropy) / float(len(entropy))
        res['ResourcesMinEntropy'] = min(entropy)
        res['ResourcesMaxEntropy'] = max(entropy)
        sizes = list(map(lambda x: x[1], resources))
        res['ResourcesMeanSize'] = sum(sizes) / float(len(sizes))
        res['ResourcesMinSize'] = min(sizes)
        res['ResourcesMaxSize'] = max(sizes)
    else:
        res['ResourcesNb'] = 0
        res['ResourcesMeanEntropy'] = 0
        res['ResourcesMinEntropy'] = 0
        res['ResourcesMaxEntropy'] = 0
        res['ResourcesMeanSize'] = 0
        res['ResourcesMinSize'] = 0
        res['ResourcesMaxSize'] = 0
    # Load configuration size
    try:
        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size
    except AttributeError:
        res['LoadConfigurationSize'] = 0

    # Version configuration size
    try:
        version_infos = get_version_info(pe)
        res['VersionInformationSize'] = len(version_infos.keys())
    except AttributeError:
        res['VersionInformationSize'] = 0
    # Sections
    res['SectionsNb'] = len(pe.sections)
    entropy = list(map(lambda x: x.get_entropy(), pe.sections))
    res['SectionsMeanEntropy'] = sum(entropy) / float(len(entropy))
    res['SectionsMinEntropy'] = min(entropy)
    res['SectionsMaxEntropy'] = max(entropy)
    raw_sizes = list(map(lambda x: x.SizeOfRawData, pe.sections))
    res['SectionsMeanRawsize'] = sum(raw_sizes) / float(len(raw_sizes))
    res['SectionsMinRawsize'] = min(raw_sizes)
    res['SectionsMaxRawsize'] = max(raw_sizes)
    virtual_sizes = list(map(lambda x: x.Misc_VirtualSize, pe.sections))
    res['SectionsMeanVirtualsize'] = sum(virtual_sizes) / float(len(virtual_sizes))
    res['SectionsMinVirtualsize'] = min(virtual_sizes)
    res['SectionMaxVirtualsize'] = max(virtual_sizes)
    try:
        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData
    except AttributeError:
        res['BaseOfData'] = 0
    # Gán giá trị cho cột 'Type' tùy theo lựa chọn 'benign' hoặc 'malware'
    res_type = file_type
        
    return {
        'FileName': name_file_PE,
        'MD5': md5_hash,
        'Type of file PE': pe_type,
        'Size of optional header': file_header.SizeOfOptionalHeader,
        'Machine': cpu_type,
        'Value of Machine': cpu_type_value,
        'Value of Characteristics': characteristics,
        'MajorLinkerVersion': major_linker_version,
        'MinorLinkerVersion': minor_linker_version,
        'SizeOfCode': size_of_code,
        'SizeOfInitializedData': size_of_initialized_data,
        'SizeOfUninitializedData': size_of_uninitialized_data,
        "AddressOfEntryPoint": pe.OPTIONAL_HEADER.AddressOfEntryPoint,
        "BaseOfCode": pe.OPTIONAL_HEADER.BaseOfCode,
        "BaseOfData": res['BaseOfData'],
        "ImageBase": pe.OPTIONAL_HEADER.ImageBase,
        "SectionAlignment": pe.OPTIONAL_HEADER.SectionAlignment,
        "FileAlignment": pe.OPTIONAL_HEADER.FileAlignment,
        "MajorOperatingSystemVersion": pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,
        "MinorOperatingSystemVersion": pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,
        "MajorImageVersion": pe.OPTIONAL_HEADER.MajorImageVersion,
        "MinorImageVersion": pe.OPTIONAL_HEADER.MinorImageVersion,
        "MajorSubsystemVersion": pe.OPTIONAL_HEADER.MajorSubsystemVersion,
        "MinorSubsystemVersion": pe.OPTIONAL_HEADER.MinorSubsystemVersion,
        "SizeOfImage": pe.OPTIONAL_HEADER.SizeOfImage,
        "SizeOfHeaders": pe.OPTIONAL_HEADER.SizeOfHeaders,
        "CheckSum": pe.OPTIONAL_HEADER.CheckSum,
        "Subsystem": pe.OPTIONAL_HEADER.Subsystem,
        "DllCharacteristics": pe.OPTIONAL_HEADER.DllCharacteristics,
        "SizeOfStackReserve": pe.OPTIONAL_HEADER.SizeOfStackReserve,
        "SizeOfStackCommit": pe.OPTIONAL_HEADER.SizeOfStackCommit,
        "SizeOfHeapReserve": pe.OPTIONAL_HEADER.SizeOfHeapReserve,
        "SizeOfHeapCommit": pe.OPTIONAL_HEADER.SizeOfHeapCommit,
        "LoaderFlags": pe.OPTIONAL_HEADER.LoaderFlags,
        "NumberOfRvaAndSizes": pe.OPTIONAL_HEADER.NumberOfRvaAndSizes,
        "SectionsNb": res['SectionsNb'],
        "SectionsMeanEntropy": res['SectionsMeanEntropy'],
        "SectionsMinEntropy":  res['SectionsMinEntropy'],
        "SectionsMaxEntropy":  res['SectionsMaxEntropy'],
        "SectionsMeanRawsize": res['SectionsMeanRawsize'],
        "SectionsMinRawsize": res['SectionsMinRawsize'],
        "SectionMaxRawsize": res['SectionsMaxRawsize'],
        "SectionsMeanVirtualsize": res['SectionsMeanVirtualsize'],
        "SectionsMinVirtualsize": res['SectionsMinVirtualsize'],
        "SectionMaxVirtualsize": res['SectionMaxVirtualsize'],
        "ImportsNbDLL": res['ImportsNbDLL'],
        "ImportsNb": res['ImportsNb'],
        "ImportsNbOrdinal": res['ImportsNbOrdinal'],
        "ExportNb": res['ExportNb'],
        "ResourcesNb": res['ResourcesNb'],
        "ResourcesMeanEntropy": res['ResourcesMeanEntropy'],
        "ResourcesMinEntropy": res['ResourcesMinEntropy'],
        "ResourcesMaxEntropy": res['ResourcesMaxEntropy'],
        "ResourcesMeanSize": res['ResourcesMeanSize'],
        "ResourcesMinSize": res['ResourcesMinSize'],
        "ResourcesMaxSize": res['ResourcesMinSize'],
        "LoadConfigurationSize": res['LoadConfigurationSize'],
        "VersionInformationSize": res['VersionInformationSize'],
        "Type": res_type
    }

# The phrase File Entropy is used to measure the amount of data which is present in a selected file. For example, if you have some files and desire to calculate the entropy value for that, then it will be very simple by accessing the methods of File Entropy and its calculation process.
def get_entropy(data):
    if len(data) == 0:
        return 0.0
    occurences = array.array('L', [0] * 256)
    for x in data:
        occurences[x if isinstance(x, int) else ord(x)] += 1

    entropy = 0
    for x in occurences:
        if x:
            p_x = float(x) / len(data)
            entropy -= p_x * math.log(p_x, 2)

    return entropy

def get_resources(pe):
    """Extract resources :
    [entropy, size]"""
    resources = []
    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
        try:
            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
                if hasattr(resource_type, 'directory'):
                    for resource_id in resource_type.directory.entries:
                        if hasattr(resource_id, 'directory'):
                            for resource_lang in resource_id.directory.entries:
                                data = pe.get_data(resource_lang.data.struct.OffsetToData,
                                                   resource_lang.data.struct.Size)
                                size = resource_lang.data.struct.Size
                                entropy = get_entropy(data)

                                resources.append([entropy, size])
        except Exception as e:
            return resources
    return resources

def extract_pe_fields_from_directory_or_file(name_file_PE, folder_path, output_path, name_file_output, file_type):

    name_file_output = os.path.join(output_path, name_file_output)
    # Tạo file CSV
    with open(name_file_output, 'w', newline='') as csvfile:
        fieldnames = [
            'FileName','MD5', 'Type of file PE', 'Size of optional header', 'Machine', 'Value of Machine', 'Value of Characteristics',
            'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData',
            "AddressOfEntryPoint", "BaseOfCode", "BaseOfData", "ImageBase", "SectionAlignment", "FileAlignment",
            "MajorOperatingSystemVersion", "MinorOperatingSystemVersion", "MajorImageVersion", "MinorImageVersion",
            "MajorSubsystemVersion", "MinorSubsystemVersion", "SizeOfImage", "SizeOfHeaders", "CheckSum", "Subsystem",
            "DllCharacteristics", "SizeOfStackReserve", "SizeOfStackCommit", "SizeOfHeapReserve", "SizeOfHeapCommit",
            "LoaderFlags", "NumberOfRvaAndSizes", "SectionsNb", "SectionsMeanEntropy", "SectionsMinEntropy",
            "SectionsMaxEntropy", "SectionsMeanRawsize", "SectionsMinRawsize", "SectionMaxRawsize",
            "SectionsMeanVirtualsize", "SectionsMinVirtualsize", "SectionMaxVirtualsize", "ImportsNbDLL",
            "ImportsNb", "ImportsNbOrdinal", "ExportNb", "ResourcesNb", "ResourcesMeanEntropy", "ResourcesMinEntropy",
            "ResourcesMaxEntropy", "ResourcesMeanSize", "ResourcesMinSize", "ResourcesMaxSize", "LoadConfigurationSize",
            "VersionInformationSize","Type"
        ]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        if os.path.exists(folder_path):
            pe_fields = extract_pe_fields(name_file_PE, folder_path,file_type)
            if pe_fields:
                writer.writerow(pe_fields)

def main():
    
    parser = argparse.ArgumentParser(description='Trích xuất thông tin file PE từ thư mục hoặc tệp.')
    parser.add_argument('name_file', help='Tên file PE của người dùng upload')
    parser.add_argument('path', help='Đường dẫn đến thư mục hoặc tệp chứa các file PE')
    parser.add_argument('result_path', help='Đường dẫn đến thư mục chứa file kết quả sau khi trích xuất')
    parser.add_argument('file_type', help='Loại file: benign hoặc malware')
    
    args = parser.parse_args()
    name_file = args.name_file
    path = args.path
    result_path = args.result_path
    file_type = args.file_type 

    # Đặt folder_path và output_path trỏ đến đường dẫn hiện tại
    folder_path = path
    output_path = result_path
    name_file_output = "output_dataset_header.csv"
    extract_pe_fields_from_directory_or_file(name_file, folder_path, output_path, name_file_output, file_type)

if __name__ == '__main__':
    main()
    
